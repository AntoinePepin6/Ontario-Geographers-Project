{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code pulls monthly climate data directly from Environment Canda's Historical Weather Data Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ontario Monthly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Decide what years to filter based on\n",
    "start_year = 1997\n",
    "end_year = 2023\n",
    "\n",
    "# URL of the server (different for each Province)\n",
    "base_url = 'https://dd.weather.gc.ca/climate/observations/monthly/csv/ON/'\n",
    "\n",
    "# Send request to get the HTML content\n",
    "response = requests.get(base_url)\n",
    "\n",
    "# Check if the request was successful (had some issues in early versions but all works now)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # This line uses the <a> tags in the HTML content to find links ending with '.csv'\n",
    "    csv_links = [link.get('href') for link in soup.find_all('a') if link.get('href').endswith('.csv')]\n",
    "\n",
    "    # Download the CSV files\n",
    "    for csv_link in csv_links:\n",
    "        \n",
    "        full_url = base_url + csv_link\n",
    "\n",
    "        # Extract the file name from the URL (last part of the link)\n",
    "        file_name = csv_link.split('/')[-1]\n",
    "\n",
    "        split_result = file_name.split('_')\n",
    "\n",
    "        # Year info is in the file name, and we'll filter out the years we aren't interested in\n",
    "        if int(split_result[4]) >= start_year and int(split_result[4]) <= end_year:\n",
    "            urlretrieve(full_url, f'C:/Users/sixte/University of Toronto/ClimateDataMonthlyON/{file_name}')\n",
    "            print(f'Downloaded: {file_name}')\n",
    "\n",
    "else:\n",
    "    print(f'Failed to retrieve with status code: {response.status_code}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quebec Monthly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Decide what years to filter based on\n",
    "start_year = 1997\n",
    "end_year = 2023\n",
    "\n",
    "# URL of the server (different for each Province)\n",
    "base_url = 'https://dd.weather.gc.ca/climate/observations/monthly/csv/MB/'\n",
    "\n",
    "# Send request to get the HTML content\n",
    "response = requests.get(base_url)\n",
    "\n",
    "# Check if the request was successful (had some issues in early versions but all works now)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # This line uses the <a> tags in the HTML content to find links ending with '.csv'\n",
    "    csv_links = [link.get('href') for link in soup.find_all('a') if link.get('href').endswith('.csv')]\n",
    "\n",
    "    # Download the CSV files\n",
    "    for csv_link in csv_links:\n",
    "        \n",
    "        full_url = base_url + csv_link\n",
    "\n",
    "        # Extract the file name from the URL (last part of the link)\n",
    "        file_name = csv_link.split('/')[-1]\n",
    "\n",
    "        split_result = file_name.split('_')\n",
    "\n",
    "        # Year info is in the file name, and we'll filter out the years we aren't interested in\n",
    "        if int(split_result[4]) >= start_year and int(split_result[4]) <= end_year:\n",
    "            urlretrieve(full_url, f'C:/Users/sixte/University of Toronto/ClimateDataMonthlyMB/{file_name}')\n",
    "            print(f'Downloaded: {file_name}')\n",
    "\n",
    "else:\n",
    "    print(f'Failed to retrieve with status code: {response.status_code}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manitoba Monthly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Decide what years to filter based on\n",
    "start_year = 1997\n",
    "end_year = 2023\n",
    "\n",
    "# URL of the server (different for each Province)\n",
    "base_url = \"https://dd.weather.gc.ca/climate/observations/monthly/csv/MB/\"\n",
    "\n",
    "# Send request to get the HTML content\n",
    "response = requests.get(base_url)\n",
    "\n",
    "# Check if the request was successful (had some issues in early versions but all works now)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # This line uses the <a> tags in the HTML content to find links ending with '.csv'\n",
    "    csv_links = [link.get(\"href\") for link in soup.find_all(\"a\") if link.get(\"href\").endswith(\".csv\")]\n",
    "\n",
    "    # Download the CSV files\n",
    "    for csv_link in csv_links:\n",
    "        \n",
    "        full_url = base_url + csv_link\n",
    "\n",
    "        # Extract the file name from the URL\n",
    "        file_name = csv_link.split(\"/\")[-1]\n",
    "\n",
    "        split_result = file_name.split(\"_\")\n",
    "\n",
    "        # Year info is in the file name, and we'll filter out the years we aren't interested in\n",
    "        if int(split_result[4]) >= start_year and int(split_result[4]) <= end_year:\n",
    "            urlretrieve(full_url, f'C:/Users/sixte/University of Toronto/ClimateDataMonthlyMB/{file_name}')\n",
    "            print(f'Downloaded: {file_name}')\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve with status code: {response.status_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
