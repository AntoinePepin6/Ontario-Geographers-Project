{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code focuses on sampling data that can be used in the model building. As the data sets contain a lot of data, the data will be sampled to reduce size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'C:/Users/sixte/University of Toronto/Antoine Pepin - Big Project/Data/Full Final DataFrames'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 1 % of data means we are still using over 2.7 million rows of data in the model training and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:/Users/sixte/University of Toronto/Antoine Pepin - Big Project/Data/Full Final DataFrames'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m dataframes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(directory_path):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      6\u001b[0m         parts \u001b[38;5;241m=\u001b[39m file_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:/Users/sixte/University of Toronto/Antoine Pepin - Big Project/Data/Full Final DataFrames'"
     ]
    }
   ],
   "source": [
    "dataframes = []\n",
    "\n",
    "for file_name in os.listdir(directory_path):\n",
    "    if file_name.endswith('.parquet'):\n",
    "        \n",
    "        parts = file_name.split('_')\n",
    "        year = int(parts[0])\n",
    "        month = int(parts[1])\n",
    "\n",
    "        if month == m and 2001 <= year <= 2018:\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            df = pd.read_parquet(file_path)\n",
    "            \n",
    "            # Perform random sampling (1% of the DataFrame)\n",
    "            sample_size = int(0.01 * len(df))\n",
    "            random_sample = df.sample(n=sample_size, random_state=42)\n",
    "            \n",
    "            dataframes.append(random_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there potentially is a trend over the years in the data (i.e. we are working with a time series), the test data is chosen as the last three of the 21 years. This is about 15 % of the data, locked away."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testframes = []\n",
    "\n",
    "for file_name in os.listdir(directory_path):\n",
    "    if file_name.endswith('.parquet'):\n",
    "        parts = file_name.split('_')\n",
    "        year = int(parts[0])\n",
    "        month = int(parts[1])\n",
    "\n",
    "        if month == m and 2019 <= year <= 2021:\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            df = pd.read_parquet(file_path)\n",
    "            \n",
    "            # Perform random sampling (1% of the DataFrame)\n",
    "            sample_size = int(0.01 * len(df))\n",
    "            random_sample = df.sample(n=sample_size, random_state=42)\n",
    "            \n",
    "            testframes.append(random_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too many of the values are NaN to be useful in a simple model\n",
    "columns_drop = ['harvested', 'BS', 'BS%']\n",
    "numericals = ['age', 'vol', 'lon', 'lat', 'Tm', 'Tx', 'Tn', 'P', 'P%N', 'Pd']\n",
    "\n",
    "for df in dataframes:\n",
    "    df[numericals] = df[numericals].astype('float32')\n",
    "    df.drop(columns=columns_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_drop = ['harvested', 'BS', 'BS%']\n",
    "numericals = ['age', 'vol', 'lon', 'lat', 'Tm', 'Tx', 'Tn', 'P', 'P%N', 'Pd']\n",
    "\n",
    "for df in testframes:\n",
    "    df[numericals] = df[numericals].astype('float32')\n",
    "    df.drop(columns=columns_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(dataframes)\n",
    "test = pd.concat(testframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 % of 15123785 * 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2722266\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 % of 15123785 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453711\n"
     ]
    }
   ],
   "source": [
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>vol</th>\n",
       "      <th>burned</th>\n",
       "      <th>dist_weight</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Tx</th>\n",
       "      <th>Tn</th>\n",
       "      <th>P</th>\n",
       "      <th>P%N</th>\n",
       "      <th>Pd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixel_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3666906</th>\n",
       "      <td>38.916668</td>\n",
       "      <td>39.546440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.465622</td>\n",
       "      <td>55.191090</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>32.099998</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11952703</th>\n",
       "      <td>97.916664</td>\n",
       "      <td>131.356522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-83.761139</td>\n",
       "      <td>49.126392</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>33.599998</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12214921</th>\n",
       "      <td>101.916664</td>\n",
       "      <td>134.552734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-84.541862</td>\n",
       "      <td>47.475681</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>29.299999</td>\n",
       "      <td>5.0</td>\n",
       "      <td>92.400002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125732</th>\n",
       "      <td>84.250000</td>\n",
       "      <td>117.746391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-92.524483</td>\n",
       "      <td>53.474644</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>3.5</td>\n",
       "      <td>100.800003</td>\n",
       "      <td>129.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3305484</th>\n",
       "      <td>66.083336</td>\n",
       "      <td>92.079544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-94.950882</td>\n",
       "      <td>51.561138</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>33.200001</td>\n",
       "      <td>2.6</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age         vol  burned  dist_weight        lon        lat  \\\n",
       "pixel_id                                                                      \n",
       "3666906    38.916668   39.546440     0.0          NaN -91.465622  55.191090   \n",
       "11952703   97.916664  131.356522     0.0          NaN -83.761139  49.126392   \n",
       "12214921  101.916664  134.552734     0.0          NaN -84.541862  47.475681   \n",
       "4125732    84.250000  117.746391     0.0          NaN -92.524483  53.474644   \n",
       "3305484    66.083336   92.079544     0.0          NaN -94.950882  51.561138   \n",
       "\n",
       "                 Tm         Tx   Tn           P    P%N    Pd  \n",
       "pixel_id                                                      \n",
       "3666906   16.400000  32.099998  2.0   80.500000    NaN  13.0  \n",
       "11952703  17.600000  33.599998  0.3         NaN    NaN   NaN  \n",
       "12214921  16.500000  29.299999  5.0   92.400002  100.0   7.0  \n",
       "4125732   17.799999  32.500000  3.5  100.800003  129.0  10.0  \n",
       "3305484   18.600000  33.200001  2.6   82.500000   93.0  12.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data):\n",
    "    feature_selected =[\n",
    "    'age', 'vol', 'Tm', 'Tx', 'Tn', 'P'\n",
    "    ]\n",
    "    return data[feature_selected]\n",
    "\n",
    "X = feature_engineering(data)\n",
    "\n",
    "# Fit and transform the data (some values are of course NaN, even in temp and percipitation. I should have thought of this before we started to assign stations to every forest pixel)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "y = data['burned']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [150],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [4],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt'],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='f1', n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search.fit(X_train, y_train) \n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "#best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(y_val, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
