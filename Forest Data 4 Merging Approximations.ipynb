{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest Data 4: Mergin Approximations to Final DataFrames\n",
    "Disclaimer, please follow notebook workflow before goind through this notebook to understand the flow or work\n",
    "\n",
    "## Overview of Notebook\n",
    "The following notebook takes in the approximatoions of age, volume and generated burned or not and harvasest or not and comiples them together in single dataframes for each year_month.At the end, these dataframes are merged with our monthly climate data to create our final dataframes for visualizatoin and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T05:19:37.170097900Z",
     "start_time": "2023-11-28T05:19:18.496417500Z"
    },
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T05:19:38.020801600Z",
     "start_time": "2023-11-28T05:19:37.181829800Z"
    }
   },
   "outputs": [],
   "source": [
    "path = r\"I:\\CME538 Project\\CME538 Project\\processed data ontario only\\250m\\Approximations\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the file names for each datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T05:19:43.759114100Z",
     "start_time": "2023-11-28T05:19:43.722155500Z"
    }
   },
   "outputs": [],
   "source": [
    "#Funciton that sorts files based on numer\n",
    "def extract_integer(filename):\n",
    "    return int(filename.split('.')[0].split('_')[1])\n",
    "\n",
    "ages = [file for file in os.listdir(path) if 'age' in file]\n",
    "ages =sorted(ages, key=extract_integer)\n",
    "print(ages)\n",
    "\n",
    "fires = [file for file in os.listdir(path) if 'fire' in file]\n",
    "fires=sorted(fires, key=extract_integer)\n",
    "print(fires)\n",
    "\n",
    "harvested = [file for file in os.listdir(path) if 'harvested' in file]\n",
    "harvested=sorted(harvested, key=extract_integer)\n",
    "print(harvested)\n",
    "\n",
    "disturbance_weights = [file for file in os.listdir(path) if 'dist' in file]\n",
    "disturbance_weights=sorted(disturbance_weights, key=extract_integer)\n",
    "print(disturbance_weights)\n",
    "\n",
    "days = [file for file in os.listdir(path) if 'day' in file]\n",
    "days=sorted(days, key=extract_integer)\n",
    "print(days)\n",
    "\n",
    "vols = [file for file in os.listdir(path) if 'day' in file]\n",
    "days=sorted(vols, key=extract_integer)\n",
    "print(vols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop through each year, and import the appropriate month column from age, vol etc to create a dataframe. the lat and lon coordinates and index pixel number is also added to keep everything in line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-28T05:35:16.523477500Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#set array to loop through\n",
    "years = np.arange(2019,2022,1)\n",
    "for year,i in zip(years,range(18,21)):\n",
    "    print(\"we are on year \",year)\n",
    "    \n",
    "    #Get month\n",
    "    months = np.arange(i+(11*i),12*(i+1),1).astype('str')\n",
    "    #months = ['0']\n",
    "    print(\"our months are \",months)\n",
    "    \n",
    "    #Start by opening the firs files which contain the first rows.\n",
    "    age = pd.read_csv(path+\"\\\\\"+ages[0],compression='gzip',usecols=months)\n",
    "    fire = pd.read_csv(path+\"\\\\\"+fires[0],compression='gzip',usecols=months)\n",
    "    harvest = pd.read_csv(path+\"\\\\\"+harvested[0],compression='gzip',usecols=months)\n",
    "    disturbance_weight = pd.read_csv(path+\"\\\\\"+disturbance_weights[0],compression='gzip',usecols=months)\n",
    "    day = pd.read_csv(path+\"\\\\\"+days[0],compression='gzip',usecols=months)\n",
    "    vol = pd.read_csv(path+\"\\\\\"+days[0],compression='gzip',usecols=months)\n",
    "    print('done intial file')\n",
    "    print('starting concat')\n",
    "    \n",
    "    #then loop throught the rest of the files in order to get a complete tabular for all pixel\n",
    "    for age_file,fire_file,harv_file,dist_file,day_file,vol_file in zip(ages[1:],fires[1:],harvested[1:],disturbance_weights[1:],days[1:],vols[1:]):\n",
    "        \n",
    "        age = pd.concat([age,pd.read_csv(path+\"\\\\\"+age_file,compression='gzip',usecols=months)]) \n",
    "        fire = pd.concat([fire,pd.read_csv(path+\"\\\\\"+fire_file,compression='gzip',usecols=months)])\n",
    "        harvest = pd.concat([harvest,pd.read_csv(path+\"\\\\\"+harv_file,compression='gzip',usecols=months)])\n",
    "        disturbance_weight = pd.concat([disturbance_weight,pd.read_csv(path+\"\\\\\"+dist_file,compression='gzip',usecols=months)])\n",
    "        day = pd.concat([day,pd.read_csv(path+\"\\\\\"+day_file,compression='gzip',usecols=months)])\n",
    "        print(len(age),len(fire),len(harvest),len(disturbance_weight),len(day))\n",
    "    \n",
    "    #create individual dataframes for each month and year based on the column from the above data\n",
    "    temp_months = ['1','2','3','4','5','6','7','8','9','10','11','12']\n",
    "    for month,temp_month in zip(months,temp_months):\n",
    "        \n",
    "        print('creating lists for each month')\n",
    "        age_list = age[month].to_list()\n",
    "        vol_list = vol[month].to_list()\n",
    "        fire_list = fire[month].to_list()\n",
    "        harv_list = harvest[month].to_list()\n",
    "        dist_list = disturbance_weight[month].to_list()\n",
    "        day_list = day[month].to_list()\n",
    "        lon = geo.lon.to_list()\n",
    "        #lon = lon[:1000000]\n",
    "        lat = geo.lat.to_list()\n",
    "        #lat = lat[:1000000]\n",
    "        geometry = geo.geometry.to_list()\n",
    "        #geometry = geometry[:1000000]\n",
    "        print('created list for month of {} in {}'.format(month,year))\n",
    "        \n",
    "        #Create final dataframe\n",
    "        data = pd.DataFrame({'age':age_list,\n",
    "                             'vol':vol_list,\n",
    "                             'burned':fire_list,\n",
    "                             'harvested':harv_list,\n",
    "                             'dist_weight':dist_list,\n",
    "                             'day':day_list,\n",
    "                             'lon':lon,\n",
    "                             'lat':lat,\n",
    "                             'geometry':geometry},\n",
    "                             columns = ['age','burned','harvested','dist_weight','day','lon','lat','geometry'])\n",
    "        \n",
    "        #AND SAVE!\n",
    "        data.to_parquet(r\"I:\\CME538 Project\\CME538 Project\\processed data ontario only\\250m\\Approximations\\compiled_dated_files\\\\\"+str(year)+\"_\"+temp_month+\".parquet\", engine=\"pyarrow\")\n",
    "        print(\"done this month and year\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate code\n",
    "This code cleans our some unwanted columns after merging with the climate data in the neareaststations notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import numpy as np\n",
    "path_vol = r\"I:\\CME538 Project\\\\processed data ontario only\\250m\\Approximations\"\n",
    "path_data = r\"I:\\CME538 Project\\\\processed data ontario only\\250m\\Approximations\\compiled_climated_files\"\n",
    "\n",
    "volume_list = [file for file in os.listdir(path_vol) if 'vol' in file]\n",
    "print(volume_list)\n",
    "\n",
    "for volume in volume_list:\n",
    "    if volume.split(\".\")[0].split(\"_\")[1] in ['2001']:\n",
    "        vol = pd.read_parquet(path_vol+\"\\\\\"+volume,engine=\"pyarrow\")\n",
    "        vol.rename(columns={0:1,1:2,2:3,3:4,4:5,5:6,6:7,7:8,8:9,9:10,10:11,11:12},inplace=True)\n",
    "        print(vol.head())\n",
    "        print(\"done openning {} volume file\".format(volume.split(\".\")[0].split(\"_\")[1]))\n",
    "    else:\n",
    "        continue\n",
    "    for file in os.listdir(path_data):    \n",
    "        print(file)\n",
    "        data = pd.read_parquet(path_data+\"\\\\\"+file,engine=\"pyarrow\")\n",
    "        print(\"done openning {} file\".format(volume.split(\".\")[0]))\n",
    "        data.index.name = 'pixel_id'\n",
    "        temp = data.groupby('pixel_id')[['Tm','Tx','Tn','P','P%N','Pd','BS','BS%']].agg(np.nanmean)\n",
    "        data.index.name = 'pixel_id'\n",
    "        data.drop(columns=['geometry','index_right','Station Name','Longitude','Latitude','Station ID','Tm','Tx','Tn','P','P%N','Pd','BS','BS%','Date'],inplace=True)\n",
    "        data.drop_duplicates(keep=\"first\",inplace=True)\n",
    "        data['vol'] = vol[int(file.split(\"_\")[1])]          \n",
    "        data=data.join(temp)\n",
    "        data = data[['age','vol','burned','harvested','dist_weight','day','lon','lat','pixel','Tm','Tx','Tn','P','P%N','Pd','BS','BS%']]\n",
    "        if len(data) > 15123785:\n",
    "            print(\"something weird with data of lenght\",len(data))\n",
    "            print(data.head())\n",
    "        else:       \n",
    "            print(\"data is good with length,\",len(data))\n",
    "            print(data.head())      \n",
    "        data.to_parquet(path_data+\"\\\\\"+file,engine=\"pyarrow\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
